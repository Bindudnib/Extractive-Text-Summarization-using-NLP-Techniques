{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwD9rgcxrK-U",
        "outputId": "a61e223c-7c6e-47d8-a9b0-8a81d457952e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_b3t2TZQjZY",
        "outputId": "9d635df3-5df9-4f7a-d7ad-c11943572f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=85e8bb287276080fd283047f47e4d2d56e4befd0830caa532a86a28093bbec1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP-sNoeJt4Bl",
        "outputId": "6f472de0-7d34-4d7d-8270-049e6638aed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries\n",
        "import nltk\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "from rouge_score import rouge_scorer\n",
        "from PyPDF2 import PdfReader\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# Download necessary NLTK packages\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Text Preprocessing Function\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)  # remove extra spaces\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
        "    text = text.lower()  # lowercase\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    words = word_tokenize(text)\n",
        "    lemmatized = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
        "    return ' '.join(lemmatized)\n",
        "\n",
        "# Input Methods\n",
        "def get_text_input():\n",
        "    print(\"Select one way of inputting your text: \")\n",
        "    print(\"1. Type your Text(or Copy-Paste)\")\n",
        "    print(\"2. Load from .txt file\")\n",
        "    print(\"3. Load from .pdf file\")\n",
        "    print(\"4. From Wikipedia Page URL\")\n",
        "    choice = input(\"\\n\")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        return input(\"Enter your text :\\n\")\n",
        "    elif choice == \"2\":\n",
        "        filepath = input(\"Enter full path of your .txt file : \")\n",
        "        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
        "            return file.read()\n",
        "    elif choice == \"3\":\n",
        "        filepath = input(\"Enter full path of your .pdf file : \")\n",
        "        reader = PdfReader(filepath)\n",
        "        return \"\\n\".join([page.extract_text() for page in reader.pages])\n",
        "    elif choice == \"4\":\n",
        "        url = input(\"Enter full Wikipedia page URL : \")\n",
        "        html = urllib.request.urlopen(url).read()\n",
        "        soup = BeautifulSoup(html, \"html.parser\")\n",
        "        return ' '.join([p.text for p in soup.find_all('p')])\n",
        "    else:\n",
        "        print(\"Invalid choice!\")\n",
        "        return \"\"\n",
        "\n",
        "# Sentence Similarity Function using TF-IDF\n",
        "def build_similarity_matrix(sentences, tfidf_matrix):\n",
        "    sim_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "    for i in range(len(sentences)):\n",
        "        for j in range(len(sentences)):\n",
        "            if i != j:\n",
        "                sim_matrix[i][j] = np.dot(tfidf_matrix[i], tfidf_matrix[j]) / (\n",
        "                    np.linalg.norm(tfidf_matrix[i]) * np.linalg.norm(tfidf_matrix[j]))\n",
        "    return sim_matrix\n",
        "\n",
        "# Generate Summary Function\n",
        "def generate_summary(text, num_sentences=3):\n",
        "    original_sentences = sent_tokenize(text)\n",
        "    cleaned_sentences = [preprocess_text(s) for s in original_sentences]\n",
        "\n",
        "    tfidf = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf.fit_transform(cleaned_sentences).toarray()\n",
        "    similarity_matrix = build_similarity_matrix(cleaned_sentences, tfidf_matrix)\n",
        "\n",
        "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
        "    scores = nx.pagerank(nx_graph)\n",
        "\n",
        "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(original_sentences)), reverse=True)\n",
        "    summary_sentences = [s for _, s in ranked_sentences[:num_sentences]]\n",
        "    return ' '.join(summary_sentences)\n",
        "\n",
        "# ROUGE Evaluation Function\n",
        "def evaluate_summary(original, summary):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(original, summary)\n",
        "\n",
        "    print(\"\\n******************** ROUGE Evaluation ********************\")\n",
        "    for metric, result in scores.items():\n",
        "        print(f\"{metric.upper()}:\")\n",
        "        print(f\"  Precision: {result.precision:.4f}\")\n",
        "        print(f\"  Recall:    {result.recall:.4f}\")\n",
        "        print(f\"  F1-Score:  {result.fmeasure:.4f}\")\n",
        "    print(\"**********************************************************\")\n",
        "\n",
        "# Main Execution\n",
        "def main():\n",
        "    text = get_text_input()\n",
        "    if not text:\n",
        "        return\n",
        "    summary = generate_summary(text, num_sentences=3)\n",
        "\n",
        "    print(\"\\n\\n******************** Summary ********************\\n\")\n",
        "    print(summary)\n",
        "    print(\"\\n\")\n",
        "    print(\"Total words in original article = \", len(text.split()))\n",
        "    print(\"Total words in summarized article = \", len(summary.split()))\n",
        "\n",
        "    evaluate_summary(text, summary)\n",
        "\n",
        "# Run it\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhA1sc5WxF9E",
        "outputId": "86909f7d-1716-4096-a4f5-3ea08634387c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Select one way of inputting your text: \n",
            "1. Type your Text(or Copy-Paste)\n",
            "2. Load from .txt file\n",
            "3. Load from .pdf file\n",
            "4. From Wikipedia Page URL\n",
            "\n",
            "1\n",
            "Enter your text :\n",
            "Agricultural production is not only fundamental to improving nutrition, but is also the main source of income for many.  Increases in crop production are key to ending hunger, as well as economic and social development.  Global crop production has changed dramatically in recent decades. The amount of food we grow has increased rapidly as a result of two drivers:  the amount of land we use for agriculture has expanded, but the largest driver has been a rapid rise in crop yields.  The diversity of diets has also increased in many countries around the world. Cereals, roots, and other staple crops once made up the majority of agricultural produce.  This has expanded into legumes, fruits, vegetables, nuts, seeds, and other foods.\n",
            "\n",
            "\n",
            "******************** Summary ********************\n",
            "\n",
            "Agricultural production is not only fundamental to improving nutrition, but is also the main source of income for many. The amount of food we grow has increased rapidly as a result of two drivers:  the amount of land we use for agriculture has expanded, but the largest driver has been a rapid rise in crop yields. Global crop production has changed dramatically in recent decades.\n",
            "\n",
            "\n",
            "Total words in original article =  120\n",
            "Total words in summarized article =  65\n",
            "\n",
            "******************** ROUGE Evaluation ********************\n",
            "ROUGE1:\n",
            "  Precision: 1.0000\n",
            "  Recall:    0.5417\n",
            "  F1-Score:  0.7027\n",
            "ROUGE2:\n",
            "  Precision: 0.9688\n",
            "  Recall:    0.5210\n",
            "  F1-Score:  0.6776\n",
            "ROUGEL:\n",
            "  Precision: 0.8923\n",
            "  Recall:    0.4833\n",
            "  F1-Score:  0.6270\n",
            "**********************************************************\n"
          ]
        }
      ]
    }
  ]
}